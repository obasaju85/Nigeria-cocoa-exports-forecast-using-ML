{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fac90c3-874e-454e-be89-cbd54019a6f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#...This is the script for econometrics techniques......\n",
    "# ============================================================\n",
    "# Econometrics: Baseline gravity + Full specification (comparable to ML)\n",
    "# - OLS on LN_EXPORT (HC1 and HAC)\n",
    "# - PPML on EXPORT (HC1)\n",
    "# - Train/Test evaluation metrics aligned with ML (R2, MAE, SMAPE)\n",
    "# - Also contains actual vs predicted cocoa exports on the logged and raw scales for the first 20 rows\n",
    "# ============================================================\n",
    "import pandas as pd\n",
    "\n",
    "data_path = \"cocoa_cleaned_dataset.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from IPython.display import display\n",
    "\n",
    "# -----------------------------\n",
    "# Config / path (use your path)\n",
    "# -----------------------------\n",
    "data_path = \"cocoa_cleaned_dataset.csv\"\n",
    "\n",
    "# -----------------------------\n",
    "# Load data\n",
    "# -----------------------------\n",
    "df = pd.read_csv(data_path)\n",
    "df = df.sort_values(['PARTNER', 'YEAR']).reset_index(drop=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Safe Feature Engineering\n",
    "# -----------------------------\n",
    "if 'LN_EXPORT' not in df.columns:\n",
    "    raise ValueError(\"Required column 'LN_EXPORT' missing from dataset.\")\n",
    "\n",
    "df['PARTNER_ENCODED'] = df.groupby('PARTNER')['LN_EXPORT'].transform('mean')\n",
    "\n",
    "if 'EXPORT' in df.columns:\n",
    "    df['LN_EXPORT_PCT_CHANGE'] = df.groupby('PARTNER')['EXPORT'].pct_change()\n",
    "    df['LN_EXPORT_PCT_CHANGE'] = np.log1p(df['LN_EXPORT_PCT_CHANGE'].fillna(0))\n",
    "\n",
    "df['LN_EXPORT_ROLL_STD3'] = df.groupby('PARTNER')['LN_EXPORT'].rolling(3, min_periods=1).std().reset_index(0, drop=True)\n",
    "\n",
    "lag_base = ['LN_EXPORT', 'LN_EXPORT_PCT_CHANGE', 'LN_EXPORT_ROLL_STD3',\n",
    "            'LN_GDP_PARTNER', 'COCOA_PRICE', 'COCOA_PRICE_SQ', 'TEMP_C', 'SPEI', 'NDVI']\n",
    "\n",
    "for col in lag_base:\n",
    "    if col in df.columns:\n",
    "        df[f'{col}_LAG1'] = df.groupby('PARTNER')[col].shift(1)\n",
    "        df[f'{col}_LAG2'] = df.groupby('PARTNER')[col].shift(2)\n",
    "\n",
    "lag_cols_created = [c for c in df.columns if c.endswith('_LAG1') or c.endswith('_LAG2')]\n",
    "for col in lag_cols_created:\n",
    "    df[col] = df[col].fillna(df.groupby('PARTNER')[col].transform('median'))\n",
    "    if df[col].isna().any():\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "if 'LN_EXPORT_LAG1' in df.columns and 'NDVI_LAG1' in df.columns:\n",
    "    df['EXPORTxNDVI'] = df['LN_EXPORT_LAG1'] * df['NDVI_LAG1']\n",
    "if 'LN_GDP_NIGERIA' in df.columns:\n",
    "    df['GDPxPARTNER'] = df['LN_GDP_NIGERIA'] * df['PARTNER_ENCODED']\n",
    "\n",
    "# -----------------------------\n",
    "# Train/Test split\n",
    "# -----------------------------\n",
    "train = df[df['YEAR'] <= 2021].copy().reset_index(drop=True)\n",
    "test  = df[df['YEAR'] >= 2022].copy().reset_index(drop=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Feature sets\n",
    "# -----------------------------\n",
    "baseline_features = ['LN_GDP_NIGERIA', 'LOG_DISTANCE', 'PARTNER_ENCODED', 'ELECTION_YEARS']\n",
    "baseline_features = [f for f in baseline_features if f in df.columns]\n",
    "\n",
    "candidate_full = (\n",
    "    lag_cols_created +\n",
    "    ['LN_GDP_NIGERIA', 'LN_GDP_PARTNER', 'LOG_DISTANCE', 'PARTNER_ENCODED',\n",
    "     'ELECTION_YEARS', 'EXPORTxNDVI', 'GDPxPARTNER',\n",
    "     'PARTNER_GOV_MEAN', 'NIGERIA_GOV_MEAN',\n",
    "     'COCOA_PRICE', 'COCOA_PRICE_SQ', 'TEMP_C', 'SPEI', 'NDVI']\n",
    ")\n",
    "full_features = [f for f in candidate_full if f in df.columns]\n",
    "\n",
    "def add_const(dfX):\n",
    "    return sm.add_constant(dfX, has_constant='add')\n",
    "\n",
    "# -----------------------------\n",
    "# Metrics helpers\n",
    "# -----------------------------\n",
    "def smape_raw(y_true_raw, y_pred_raw):\n",
    "    a = np.abs(y_pred_raw - y_true_raw)\n",
    "    denom = (np.abs(y_true_raw) + np.abs(y_pred_raw) + 1e-10)\n",
    "    return 100.0 / len(y_true_raw) * np.sum(2.0 * a / denom)\n",
    "\n",
    "def eval_metrics_logspace(name, y_tr_log, y_tr_pred_log, y_te_log, y_te_pred_log):\n",
    "    return {\n",
    "        \"Model\": name,\n",
    "        \"Train R2\": r2_score(y_tr_log, y_tr_pred_log),\n",
    "        \"Test R2\": r2_score(y_te_log, y_te_pred_log),\n",
    "        \"Train MAE\": mean_absolute_error(y_tr_log, y_tr_pred_log),\n",
    "        \"Test MAE\": mean_absolute_error(y_te_log, y_te_pred_log),\n",
    "        \"Train SMAPE (EXPORT%)\": smape_raw(np.exp(y_tr_log), np.exp(y_tr_pred_log)),\n",
    "        \"Test SMAPE (EXPORT%)\": smape_raw(np.exp(y_te_log), np.exp(y_te_pred_log))\n",
    "    }\n",
    "\n",
    "def eval_metrics_levelspace(name, y_tr_lvl, y_tr_pred_lvl, y_te_lvl, y_te_pred_lvl):\n",
    "    return {\n",
    "        \"Model\": name,\n",
    "        \"Train R2\": np.nan,\n",
    "        \"Test R2\": np.nan,\n",
    "        \"Train MAE (level)\": mean_absolute_error(y_tr_lvl, y_tr_pred_lvl),\n",
    "        \"Test MAE (level)\": mean_absolute_error(y_te_lvl, y_te_pred_lvl),\n",
    "        \"Train SMAPE (EXPORT%)\": smape_raw(y_tr_lvl, y_tr_pred_lvl),\n",
    "        \"Test SMAPE (EXPORT%)\": smape_raw(y_te_lvl, y_te_pred_lvl)\n",
    "    }\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Baseline OLS\n",
    "# -----------------------------\n",
    "metrics_list = []\n",
    "coef_tables = {}\n",
    "\n",
    "if len(baseline_features) > 0:\n",
    "    X_tr_base = add_const(train[baseline_features])\n",
    "    X_te_base = add_const(test[baseline_features])\n",
    "\n",
    "    y_tr_ln = train['LN_EXPORT']\n",
    "    y_te_ln = test['LN_EXPORT']\n",
    "\n",
    "    ols_base = sm.OLS(y_tr_ln, X_tr_base).fit()\n",
    "    ols_base_hc1 = ols_base.get_robustcov_results(cov_type=\"HC1\")\n",
    "\n",
    "    y_tr_pred_ln = ols_base.predict(X_tr_base)\n",
    "    y_te_pred_ln = ols_base.predict(X_te_base)\n",
    "\n",
    "    metrics_list.append(eval_metrics_logspace(\"OLS_baseline\", y_tr_ln, y_tr_pred_ln, y_te_ln, y_te_pred_ln))\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Baseline PPML\n",
    "# -----------------------------\n",
    "if len(baseline_features) > 0 and 'EXPORT' in train.columns:\n",
    "    X_tr_base_lvl = add_const(train[baseline_features])\n",
    "    X_te_base_lvl = add_const(test[baseline_features])\n",
    "\n",
    "    y_tr_lvl = train['EXPORT'].clip(lower=1e-6)\n",
    "    y_te_lvl = test['EXPORT'].clip(lower=1e-6)\n",
    "\n",
    "    ppml_base = sm.GLM(y_tr_lvl, X_tr_base_lvl, family=sm.families.Poisson()).fit(cov_type=\"HC1\")\n",
    "\n",
    "    y_tr_ppml_pred = ppml_base.predict(X_tr_base_lvl)\n",
    "    y_te_ppml_pred = ppml_base.predict(X_te_base_lvl)\n",
    "\n",
    "    metrics_list.append(eval_metrics_levelspace(\"PPML_baseline\", y_tr_lvl, y_tr_ppml_pred, y_te_lvl, y_te_ppml_pred))\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Full specification (OLS + PPML)\n",
    "# -----------------------------\n",
    "if len(full_features) > 0:\n",
    "    X_tr_full = add_const(train[full_features])\n",
    "    X_te_full = add_const(test[full_features])\n",
    "\n",
    "    ols_full = sm.OLS(train['LN_EXPORT'], X_tr_full).fit()\n",
    "    y_tr_pred_full = ols_full.predict(X_tr_full)\n",
    "    y_te_pred_full = ols_full.predict(X_te_full)\n",
    "    metrics_list.append(eval_metrics_logspace(\"OLS_full\", train['LN_EXPORT'], y_tr_pred_full, test['LN_EXPORT'], y_te_pred_full))\n",
    "\n",
    "    if 'EXPORT' in train.columns:\n",
    "        ppml_full = sm.GLM(train['EXPORT'].clip(lower=1e-6), X_tr_full, family=sm.families.Poisson()).fit(cov_type=\"HC1\")\n",
    "        y_tr_ppml_full = ppml_full.predict(X_tr_full)\n",
    "        y_te_ppml_full = ppml_full.predict(X_te_full)\n",
    "        metrics_list.append(eval_metrics_levelspace(\"PPML_full\", train['EXPORT'].clip(lower=1e-6), y_tr_ppml_full,\n",
    "                                                   test['EXPORT'].clip(lower=1e-6), y_te_ppml_full))\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Display results\n",
    "# -----------------------------\n",
    "metrics_df = pd.DataFrame(metrics_list)\n",
    "cols_order = [c for c in [\"Model\", \"Train R2\", \"Test R2\", \"Train MAE\", \"Test MAE\",\n",
    "                          \"Train MAE (level)\", \"Test MAE (level)\",\n",
    "                          \"Train SMAPE (EXPORT%)\", \"Test SMAPE (EXPORT%)\"] if c in metrics_df.columns]\n",
    "metrics_df = metrics_df[cols_order]\n",
    "\n",
    "print(\"\\n📊 Econometrics Metrics (comparable with ML):\")\n",
    "display(metrics_df)\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Actual vs Predicted (first 20 rows)\n",
    "# -----------------------------\n",
    "test_display = test[['YEAR', 'PARTNER', 'EXPORT', 'LN_EXPORT']].copy()\n",
    "\n",
    "if 'y_te_pred_ln' in locals():\n",
    "    test_display['PRED_OLS_baseline_LOG'] = y_te_pred_ln.values\n",
    "if 'y_te_ppml_pred' in locals():\n",
    "    test_display['PRED_PPML_baseline_LEVEL'] = y_te_ppml_pred.values\n",
    "if 'y_te_pred_full' in locals():\n",
    "    test_display['PRED_OLS_full_LOG'] = y_te_pred_full.values\n",
    "if 'y_te_ppml_full' in locals():\n",
    "    test_display['PRED_PPML_full_LEVEL'] = y_te_ppml_full.values\n",
    "\n",
    "if 'PRED_OLS_baseline_LOG' in test_display.columns:\n",
    "    test_display['PRED_OLS_baseline_EXPORT'] = np.exp(test_display['PRED_OLS_baseline_LOG'])\n",
    "if 'PRED_OLS_full_LOG' in test_display.columns:\n",
    "    test_display['PRED_OLS_full_EXPORT'] = np.exp(test_display['PRED_OLS_full_LOG'])\n",
    "\n",
    "print(\"\\n📈 Actual vs Predicted (test) — first 20 rows:\")\n",
    "display(test_display.head(20))\n",
    "\n",
    "# -----------------------------\n",
    "# Done\n",
    "# -----------------------------\n",
    "print(\"\\nDone. Baseline and full-spec econometrics results successfully generated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3341e7-3352-43c4-a275-1c150b37a030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# ML + SHAP + Robustness Pipeline (SMAPE on raw EXPORT scale)\n",
    "# End-to-end (run in Jupyter)\n",
    "# ============================\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "# ML libs\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import RidgeCV, LassoCV, LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Diagnostics\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# SHAP\n",
    "try:\n",
    "    import shap\n",
    "    HAS_SHAP = True\n",
    "except Exception:\n",
    "    HAS_SHAP = False\n",
    "    print(\"⚠️ shap not installed. Install with `pip install shap` to enable SHAP analysis.\")\n",
    "\n",
    "# -----------------------------\n",
    "# Paths / outputs\n",
    "# -----------------------------\n",
    "data_path = \"cocoa_cleaned_dataset.csv\"\n",
    "out_dir = r\".\\model_outputs\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Load dataset\n",
    "# -----------------------------\n",
    "df = pd.read_csv(data_path)\n",
    "df = df.sort_values(['PARTNER', 'YEAR']).reset_index(drop=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Feature engineering\n",
    "# -----------------------------\n",
    "df['LN_EXPORT_PCT_CHANGE'] = df.groupby('PARTNER')['EXPORT'].pct_change()\n",
    "df['LN_EXPORT_PCT_CHANGE'] = np.log1p(df['LN_EXPORT_PCT_CHANGE'].fillna(0))\n",
    "\n",
    "df['LN_EXPORT_ROLL_STD3'] = (\n",
    "    df.groupby('PARTNER')['LN_EXPORT'].rolling(3, min_periods=1).std().reset_index(0, drop=True)\n",
    ")\n",
    "\n",
    "lag_cols = [\n",
    "    'LN_EXPORT', 'LN_EXPORT_PCT_CHANGE', 'LN_EXPORT_ROLL_STD3',\n",
    "    'LN_GDP_PARTNER', 'COCOA_PRICE', 'COCOA_PRICE_SQ',\n",
    "    'TEMP_C', 'SPEI', 'NDVI'\n",
    "]\n",
    "\n",
    "for col in lag_cols:\n",
    "    if col in df.columns:\n",
    "        df[f'{col}_LAG1'] = df.groupby('PARTNER')[col].shift(1)\n",
    "        df[f'{col}_LAG2'] = df.groupby('PARTNER')[col].shift(2)\n",
    "\n",
    "# Fill NaNs in lagged features with median\n",
    "for col in df.columns:\n",
    "    if '_LAG' in col:\n",
    "        df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "# Partner encoding\n",
    "partner_means = df.groupby('PARTNER')['LN_EXPORT'].mean()\n",
    "df['PARTNER_ENCODED'] = df['PARTNER'].map(partner_means)\n",
    "\n",
    "# Interaction features\n",
    "if 'LN_EXPORT_LAG1' in df.columns and 'NDVI_LAG1' in df.columns:\n",
    "    df['EXPORTxNDVI'] = df['LN_EXPORT_LAG1'] * df['NDVI_LAG1']\n",
    "else:\n",
    "    if 'EXPORTxNDVI' not in df.columns:\n",
    "        df['EXPORTxNDVI'] = np.nan\n",
    "\n",
    "if 'LN_GDP_NIGERIA' in df.columns:\n",
    "    df['GDPxPARTNER'] = df['LN_GDP_NIGERIA'] * df['PARTNER_ENCODED']\n",
    "else:\n",
    "    if 'GDPxPARTNER' not in df.columns:\n",
    "        df['GDPxPARTNER'] = np.nan\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Train/Test Split\n",
    "# -----------------------------\n",
    "train = df[df['YEAR'] <= 2021].copy().reset_index(drop=True)\n",
    "test  = df[df['YEAR'] >= 2022].copy().reset_index(drop=True)\n",
    "\n",
    "features = [\n",
    "    c for c in df.columns if '_LAG' in c or c in [\n",
    "        'LN_GDP_NIGERIA', 'GDP_INTERACTION',\n",
    "        'PARTNER_GOV_MEAN', 'NIGERIA_GOV_MEAN',\n",
    "        'LOG_DISTANCE', 'PARTNER_ENCODED',\n",
    "        'ELECTION_YEARS', 'EXPORTxNDVI', 'GDPxPARTNER'\n",
    "    ]\n",
    "]\n",
    "features = [f for f in features if f in df.columns]\n",
    "target = 'LN_EXPORT'\n",
    "X_train, y_train = train[features], train[target]\n",
    "X_test,  y_test  = test[features],  test[target]\n",
    "\n",
    "# -----------------------------\n",
    "# 4) SMAPE on raw EXPORT scale\n",
    "# -----------------------------\n",
    "def smape_raw(y_true_log, y_pred_log):\n",
    "    y_true = np.expm1(y_true_log)\n",
    "    y_pred = np.expm1(y_pred_log)\n",
    "    return 100 / len(y_true) * np.sum(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))\n",
    "\n",
    "# -----------------------------\n",
    "# 5) ML training\n",
    "# -----------------------------\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Random Forest\n",
    "rf_param_grid = {\n",
    "    \"n_estimators\": [200, 400, 600],\n",
    "    \"max_depth\": [4, 6, 8],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"max_features\": [\"sqrt\", \"log2\", 0.8]\n",
    "}\n",
    "rf = RandomForestRegressor(random_state=RANDOM_STATE)\n",
    "rf_grid = GridSearchCV(rf, rf_param_grid, cv=tscv, scoring=\"r2\", n_jobs=-1, verbose=1)\n",
    "rf_grid.fit(X_train, y_train)\n",
    "best_rf = rf_grid.best_estimator_\n",
    "\n",
    "train['PRED_RF'] = best_rf.predict(X_train)\n",
    "test['PRED_RF']  = best_rf.predict(X_test)\n",
    "\n",
    "# XGBoost\n",
    "xgb = XGBRegressor(objective=\"reg:squarederror\", random_state=RANDOM_STATE)\n",
    "xgb_param_grid = {\n",
    "    \"n_estimators\": [200, 400, 600],\n",
    "    \"max_depth\": [3, 5, 6],\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "    \"subsample\": [0.7, 0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.7, 0.8, 1.0],\n",
    "    \"reg_alpha\": [0, 0.01, 0.1],\n",
    "    \"reg_lambda\": [1, 1.5, 2]\n",
    "}\n",
    "xgb_grid = GridSearchCV(xgb, xgb_param_grid, cv=tscv, scoring=\"r2\", n_jobs=-1, verbose=1)\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "best_xgb = xgb_grid.best_estimator_\n",
    "\n",
    "train['PRED_XGB'] = best_xgb.predict(X_train)\n",
    "test['PRED_XGB']  = best_xgb.predict(X_test)\n",
    "\n",
    "# RidgeCV and LassoCV\n",
    "ridge = RidgeCV(alphas=[0.1, 1.0, 10.0], cv=tscv)\n",
    "ridge.fit(X_train, y_train)\n",
    "train['PRED_Ridge'] = ridge.predict(X_train)\n",
    "test['PRED_Ridge']  = ridge.predict(X_test)\n",
    "\n",
    "lasso = LassoCV(alphas=[0.01, 0.1, 1.0], cv=tscv, max_iter=5000)\n",
    "lasso.fit(X_train, y_train)\n",
    "train['PRED_Lasso'] = lasso.predict(X_train)\n",
    "test['PRED_Lasso']  = lasso.predict(X_test)\n",
    "\n",
    "# Ensemble\n",
    "weights = {\"RF\": 0.4, \"XGB\": 0.4, \"Ridge\": 0.2}\n",
    "train['PRED_ENS'] = train['PRED_RF']*weights[\"RF\"] + train['PRED_XGB']*weights[\"XGB\"] + train['PRED_Ridge']*weights[\"Ridge\"]\n",
    "test['PRED_ENS']  = test['PRED_RF']*weights[\"RF\"] + test['PRED_XGB']*weights[\"XGB\"] + test['PRED_Ridge']*weights[\"Ridge\"]\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Evaluation\n",
    "# -----------------------------\n",
    "def evaluate(model_name, y_train, y_train_pred, y_test, y_test_pred):\n",
    "    return {\n",
    "        \"Model\": model_name,\n",
    "        \"Train R²\": r2_score(y_train, y_train_pred),\n",
    "        \"Test R²\": r2_score(y_test, y_test_pred),\n",
    "        \"Train MAE\": mean_absolute_error(y_train, y_train_pred),\n",
    "        \"Test MAE\": mean_absolute_error(y_test, y_test_pred),\n",
    "        \"Train SMAPE\": smape_raw(y_train, y_train_pred),\n",
    "        \"Test SMAPE\": smape_raw(y_test, y_test_pred)\n",
    "    }\n",
    "\n",
    "results = []\n",
    "results.append(evaluate(\"RF\",    y_train, train['PRED_RF'],    y_test, test['PRED_RF']))\n",
    "results.append(evaluate(\"XGB\",   y_train, train['PRED_XGB'],   y_test, test['PRED_XGB']))\n",
    "results.append(evaluate(\"Ridge\", y_train, train['PRED_Ridge'], y_test, test['PRED_Ridge']))\n",
    "results.append(evaluate(\"Lasso\", y_train, train['PRED_Lasso'], y_test, test['PRED_Lasso']))\n",
    "results.append(evaluate(\"ENS\",   y_train, train['PRED_ENS'],   y_test, test['PRED_ENS']))\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df[\"R2_Gap\"] = results_df[\"Train R²\"] - results_df[\"Test R²\"]\n",
    "\n",
    "print(\"\\n📊 Model Comparison:\")\n",
    "display(results_df)\n",
    "results_df.to_csv(os.path.join(out_dir, \"ml_model_comparison.csv\"), index=False)\n",
    "\n",
    "# -----------------------------\n",
    "# 7) Rolling-window CV (SMAPE raw)\n",
    "# -----------------------------\n",
    "years = sorted(df['YEAR'].unique())\n",
    "cv_results = []\n",
    "for year in years[5:]:\n",
    "    train_cv = df[df['YEAR'] < year]\n",
    "    test_cv  = df[df['YEAR'] == year]\n",
    "    if train_cv.empty or test_cv.empty:\n",
    "        continue\n",
    "    X_tr, y_tr = train_cv[features], train_cv[target]\n",
    "    X_te, y_te = test_cv[features], test_cv[target]\n",
    "    try:\n",
    "        best_rf.fit(X_tr, y_tr)\n",
    "        y_pred_rf = best_rf.predict(X_te)\n",
    "        cv_results.append({\n",
    "            \"YEAR\": year,\n",
    "            \"R2_RF\": r2_score(y_te, y_pred_rf),\n",
    "            \"SMAPE_RF\": smape_raw(y_te, y_pred_rf)\n",
    "        })\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "cv_df = pd.DataFrame(cv_results)\n",
    "print(\"\\n🔄 Rolling-window CV results:\")\n",
    "display(cv_df)\n",
    "cv_df.to_csv(os.path.join(out_dir, \"rolling_cv_summary.csv\"), index=False)\n",
    "\n",
    "# -----------------------------\n",
    "# 8) Feature importances\n",
    "# -----------------------------\n",
    "print(\"\\n🔥 Full RF Feature Importances:\")\n",
    "rf_importances = pd.Series(best_rf.feature_importances_, index=features).sort_values(ascending=False)\n",
    "display(rf_importances)\n",
    "rf_importances.to_csv(os.path.join(out_dir, \"rf_feature_importances.csv\"))\n",
    "\n",
    "print(\"\\n🔥 Full XGB Feature Importances:\")\n",
    "xgb_importances = pd.Series(best_xgb.feature_importances_, index=features).sort_values(ascending=False)\n",
    "display(xgb_importances)\n",
    "xgb_importances.to_csv(os.path.join(out_dir, \"xgb_feature_importances.csv\"))\n",
    "\n",
    "# -----------------------------\n",
    "# 9) Residuals & Bias\n",
    "# -----------------------------\n",
    "test['RESID_RF']    = y_test - test['PRED_RF']\n",
    "test['RESID_XGB']   = y_test - test['PRED_XGB']\n",
    "test['RESID_Ridge'] = y_test - test['PRED_Ridge']\n",
    "test['RESID_Lasso'] = y_test - test['PRED_Lasso']\n",
    "test['RESID_ENS']   = y_test - test['PRED_ENS']\n",
    "\n",
    "print(\"\\n📉 Residual Mean (Bias Check):\")\n",
    "display(test[['RESID_RF', 'RESID_XGB', 'RESID_Ridge', 'RESID_Lasso', 'RESID_ENS']].mean())\n",
    "\n",
    "# -----------------------------\n",
    "# 10) SHAP Analysis\n",
    "# -----------------------------\n",
    "if HAS_SHAP:\n",
    "    explainer_rf = shap.TreeExplainer(best_rf)\n",
    "    explainer_xgb = shap.TreeExplainer(best_xgb)\n",
    "\n",
    "    shap_values_rf = explainer_rf.shap_values(X_test)\n",
    "    shap_values_xgb = explainer_xgb.shap_values(X_test)\n",
    "\n",
    "    shap_imp_rf = pd.DataFrame({\n",
    "        \"feature\": X_test.columns,\n",
    "        \"mean_abs_shap\": np.abs(shap_values_rf).mean(axis=0)\n",
    "    }).sort_values(\"mean_abs_shap\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    shap_imp_xgb = pd.DataFrame({\n",
    "        \"feature\": X_test.columns,\n",
    "        \"mean_abs_shap\": np.abs(shap_values_xgb).mean(axis=0)\n",
    "    }).sort_values(\"mean_abs_shap\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    print(\"\\n🔥 SHAP (RF) mean |SHAP| table (full ranking):\")\n",
    "    display(shap_imp_rf)\n",
    "    shap_imp_rf.to_csv(os.path.join(out_dir, \"shap_rf_meanabs.csv\"), index=False)\n",
    "\n",
    "    print(\"\\n🔥 SHAP (XGB) mean |SHAP| table (full ranking):\")\n",
    "    display(shap_imp_xgb)\n",
    "    shap_imp_xgb.to_csv(os.path.join(out_dir, \"shap_xgb_meanabs.csv\"), index=False)\n",
    "\n",
    "    # Visualizations\n",
    "    plt.figure(figsize=(10,6))\n",
    "    shap.summary_plot(shap_values_rf, X_test, plot_type=\"bar\", show=False)\n",
    "    plt.title(\"RF – Mean SHAP Importance\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(out_dir, \"shap_rf_bar.png\"))\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    shap.summary_plot(shap_values_xgb, X_test, plot_type=\"bar\", show=False)\n",
    "    plt.title(\"XGB – Mean SHAP Importance\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(out_dir, \"shap_xgb_bar.png\"))\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"⚠️ SHAP not available — skip SHAP steps.\")\n",
    "\n",
    "# -----------------------------\n",
    "# 11) Robustness checks\n",
    "# -----------------------------\n",
    "# 11.1 Naive Lag-only baseline\n",
    "naive_results = None\n",
    "if 'LN_EXPORT_LAG1' in train.columns:\n",
    "    lr_naive = LinearRegression()\n",
    "    Xn_train = train[['LN_EXPORT_LAG1']].fillna(0)\n",
    "    Xn_test  = test[['LN_EXPORT_LAG1']].fillna(0)\n",
    "    lr_naive.fit(Xn_train, train[target])\n",
    "    y_tr_naive = lr_naive.predict(Xn_train)\n",
    "    y_te_naive = lr_naive.predict(Xn_test)\n",
    "    naive_results = {\n",
    "        \"Model\": \"Naive (Lag1)\",\n",
    "        \"Train R²\": r2_score(train[target], y_tr_naive),\n",
    "        \"Test R²\": r2_score(test[target], y_te_naive),\n",
    "        \"Train MAE\": mean_absolute_error(train[target], y_tr_naive),\n",
    "        \"Test MAE\": mean_absolute_error(test[target], y_te_naive),\n",
    "        \"Train SMAPE\": smape_raw(train[target], y_tr_naive),\n",
    "        \"Test SMAPE\": smape_raw(test[target], y_te_naive)\n",
    "    }\n",
    "    print(\"\\n🔰 Naïve benchmark (Lag1):\")\n",
    "    display(pd.DataFrame([naive_results]))\n",
    "\n",
    "# 11.2 Permutation importance\n",
    "perm_importance_tables = {}\n",
    "for name, model in [(\"RF\", best_rf), (\"XGB\", best_xgb)]:\n",
    "    try:\n",
    "        perm = permutation_importance(model, X_train, y_train, n_repeats=20, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "        perm_df = pd.DataFrame({\n",
    "            \"feature\": X_train.columns,\n",
    "            \"importance_mean\": perm.importances_mean,\n",
    "            \"importance_std\": perm.importances_std\n",
    "        }).sort_values(\"importance_mean\", ascending=False).reset_index(drop=True)\n",
    "        perm_importance_tables[name] = perm_df\n",
    "        print(f\"\\n🔁 Permutation importance ({name}):\")\n",
    "        display(perm_df)\n",
    "        perm_df.to_csv(os.path.join(out_dir, f\"perm_importance_{name}.csv\"), index=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Permutation importance failed for {name}: {e}\")\n",
    "\n",
    "# 11.3 Durbin-Watson on residuals\n",
    "dw = {}\n",
    "try:\n",
    "    dw['RF'] = durbin_watson(test['RESID_RF'].dropna())\n",
    "    dw['XGB'] = durbin_watson(test['RESID_XGB'].dropna())\n",
    "    dw['Ridge'] = durbin_watson(test['RESID_Ridge'].dropna())\n",
    "    print(\"\\n📈 Durbin-Watson statistics (test residuals):\")\n",
    "    display(pd.Series(dw).to_frame(\"DurbinWatson\"))\n",
    "except Exception as e:\n",
    "    print(\"Durbin-Watson failed:\", e)\n",
    "\n",
    "# 11.4 Bootstrapped metrics\n",
    "def bootstrap_metrics_on_test(model, X_test_df, y_test_ser, n_boot=200, random_state=RANDOM_STATE):\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    rows = X_test_df.index.values\n",
    "    out = []\n",
    "    for i in range(n_boot):\n",
    "        idx = rng.choice(rows, size=len(rows), replace=True)\n",
    "        Xi = X_test_df.loc[idx]\n",
    "        yi = y_test_ser.loc[idx]\n",
    "        pred = model.predict(Xi)\n",
    "        out.append({\n",
    "            \"R2\": r2_score(yi, pred),\n",
    "            \"MAE\": mean_absolute_error(yi, pred),\n",
    "            \"SMAPE\": smape_raw(yi, pred)\n",
    "        })\n",
    "    return pd.DataFrame(out)\n",
    "\n",
    "bootstrap_summary = {}\n",
    "for name, model in [(\"RF\", best_rf), (\"XGB\", best_xgb), (\"Ridge\", ridge)]:\n",
    "    try:\n",
    "        bdf = bootstrap_metrics_on_test(model, X_test, y_test, n_boot=200)\n",
    "        bootstrap_summary[name] = bdf.describe().loc[['mean','std']]\n",
    "        print(f\"\\n🎲 Bootstrap summary ({name}) — mean & std of metrics on test resamples:\")\n",
    "        display(bdf.describe().loc[['mean','std']])\n",
    "        bdf.to_csv(os.path.join(out_dir, f\"bootstrap_metrics_{name}.csv\"), index=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Bootstrap failed for {name}: {e}\")\n",
    "\n",
    "# Save main ML results\n",
    "results_df.to_csv(os.path.join(out_dir, \"ml_model_comparison.csv\"), index=False)\n",
    "print(\"\\nDone. All ML + SHAP (if installed) + robustness outputs saved to\", out_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
